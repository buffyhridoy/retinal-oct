{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom collections import defaultdict\nimport seaborn as sns\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport tensorflow_addons as tfa","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:30.869816Z","iopub.execute_input":"2022-08-17T09:08:30.870221Z","iopub.status.idle":"2022-08-17T09:08:36.954692Z","shell.execute_reply.started":"2022-08-17T09:08:30.870131Z","shell.execute_reply":"2022-08-17T09:08:36.953842Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_path = \"/kaggle/input/kermany2018/OCT2017 /train\"\nval_path = \"/kaggle/input/kermany2018/OCT2017 /val\"\ntest_path = \"/kaggle/input/kermany2018/OCT2017 /test\"","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:36.956967Z","iopub.execute_input":"2022-08-17T09:08:36.957578Z","iopub.status.idle":"2022-08-17T09:08:36.962007Z","shell.execute_reply.started":"2022-08-17T09:08:36.957540Z","shell.execute_reply":"2022-08-17T09:08:36.960970Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom PIL import Image\nfrom collections import defaultdict\n\nX_train = []\nY_train = []\n\nfor target in os.listdir(train_path):\n    target_path = os.path.join(train_path, target)\n    for file in tqdm(os.listdir(target_path)):\n        file_path = os.path.join(target_path, file)\n        X_train.append(file_path)\n        Y_train.append(target)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:36.964090Z","iopub.execute_input":"2022-08-17T09:08:36.964453Z","iopub.status.idle":"2022-08-17T09:08:38.639120Z","shell.execute_reply.started":"2022-08-17T09:08:36.964414Z","shell.execute_reply":"2022-08-17T09:08:38.638276Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom PIL import Image\nfrom collections import defaultdict\n\nX_val = []\nY_val = []\n\nfor target in os.listdir(val_path):\n    target_path = os.path.join(val_path, target)\n    for file in tqdm(os.listdir(target_path)):\n        file_path = os.path.join(target_path, file)\n        X_val.append(file_path)\n        Y_val.append(target)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:38.640804Z","iopub.execute_input":"2022-08-17T09:08:38.641459Z","iopub.status.idle":"2022-08-17T09:08:38.682363Z","shell.execute_reply.started":"2022-08-17T09:08:38.641415Z","shell.execute_reply":"2022-08-17T09:08:38.681445Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom PIL import Image\nfrom collections import defaultdict\n\nX_test = []\nY_test = []\n\nfor target in os.listdir(test_path):\n    target_path = os.path.join(test_path, target)\n    for file in tqdm(os.listdir(target_path)):\n        file_path = os.path.join(target_path, file)\n        X_test.append(file_path)\n        Y_test.append(target)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:38.683707Z","iopub.execute_input":"2022-08-17T09:08:38.684059Z","iopub.status.idle":"2022-08-17T09:08:38.777932Z","shell.execute_reply.started":"2022-08-17T09:08:38.684002Z","shell.execute_reply":"2022-08-17T09:08:38.777096Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:38.779058Z","iopub.execute_input":"2022-08-17T09:08:38.779402Z","iopub.status.idle":"2022-08-17T09:08:39.073962Z","shell.execute_reply.started":"2022-08-17T09:08:38.779370Z","shell.execute_reply":"2022-08-17T09:08:39.073029Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = Y_val)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:39.075347Z","iopub.execute_input":"2022-08-17T09:08:39.075697Z","iopub.status.idle":"2022-08-17T09:08:39.200116Z","shell.execute_reply.started":"2022-08-17T09:08:39.075660Z","shell.execute_reply":"2022-08-17T09:08:39.199153Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x = Y_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:39.202854Z","iopub.execute_input":"2022-08-17T09:08:39.203222Z","iopub.status.idle":"2022-08-17T09:08:39.320711Z","shell.execute_reply.started":"2022-08-17T09:08:39.203185Z","shell.execute_reply":"2022-08-17T09:08:39.319975Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_train = pd.DataFrame(list(zip(X_train, Y_train)), columns =['image_path', 'label'])\ndf_val = pd.DataFrame(list(zip(X_val, Y_val)), columns =['image_path', 'label'])\ndf_test = pd.DataFrame(list(zip(X_test, Y_test)), columns =['image_path', 'label'])","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:39.322559Z","iopub.execute_input":"2022-08-17T09:08:39.322917Z","iopub.status.idle":"2022-08-17T09:08:39.511209Z","shell.execute_reply.started":"2022-08-17T09:08:39.322881Z","shell.execute_reply":"2022-08-17T09:08:39.510362Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_aug = ImageDataGenerator(\n    horizontal_flip=True,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    zoom_range=0.05,\n    rescale = 1./255,\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n)\n\ntest_aug = ImageDataGenerator(\n    rescale = 1./255,\n    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n)\n\ntrain_generator= train_aug.flow_from_dataframe(\n    dataframe=df_train,\n    x_col=\"image_path\",\n    y_col=\"label\",\n    batch_size=16,\n    color_mode=\"rgb\",\n    target_size = (224, 224),\n    class_mode=\"categorical\")\n\nval_generator= test_aug.flow_from_dataframe(\n    dataframe=df_val,\n    x_col=\"image_path\",\n    y_col=\"label\",\n    batch_size=16,\n    color_mode=\"rgb\",\n    target_size = (224, 224),\n    class_mode=\"categorical\")\n\ntest_generator= test_aug.flow_from_dataframe(\n    dataframe=df_test,\n    x_col=\"image_path\",\n    y_col=\"label\",\n    color_mode=\"rgb\",\n    batch_size=16,\n    shuffle = False, \n    target_size = (224, 224),\n    class_mode=\"categorical\")","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:08:39.512368Z","iopub.execute_input":"2022-08-17T09:08:39.512622Z","iopub.status.idle":"2022-08-17T09:09:34.370656Z","shell.execute_reply.started":"2022-08-17T09:08:39.512596Z","shell.execute_reply":"2022-08-17T09:09:34.369765Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D,AveragePooling2D, BatchNormalization, PReLU, ReLU\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import ResNet50, InceptionResNetV2\n\ndef generate_model(pretrained_model = 'vgg16', num_classes=4):\n    if pretrained_model == 'inceptionv3':\n        base_model = InceptionV3(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3))\n    elif pretrained_model == 'inceptionresnet':\n        base_model = InceptionResNetV2(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3))\n    else:\n        base_model = VGG16(weights = 'imagenet', include_top=False, input_shape=(224, 224, 3)) # Topless\n    \n    x = base_model.output\n    x = Flatten()(x)\n    x = Dense(4096)(x)\n    x = ReLU()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(4096)(x)\n    x = ReLU()(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    #Freezing Convolutional Base\n    for layer in base_model.layers[:-3]:\n        layer.trainable = False  \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:09:34.371964Z","iopub.execute_input":"2022-08-17T09:09:34.372327Z","iopub.status.idle":"2022-08-17T09:09:34.381529Z","shell.execute_reply.started":"2022-08-17T09:09:34.372287Z","shell.execute_reply":"2022-08-17T09:09:34.380550Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_generator, test_generator, num_epochs, optimizer, metrics):\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=optimizer, \n                  metrics=metrics)\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=6, verbose=1)\n    rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=7)\n    print(model.summary())\n    \n    history = model.fit(train_generator, epochs=num_epochs, \n                        validation_data=test_generator, verbose=1,\n                        callbacks = [early_stop, rlr])\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:09:34.383135Z","iopub.execute_input":"2022-08-17T09:09:34.383805Z","iopub.status.idle":"2022-08-17T09:09:34.395753Z","shell.execute_reply.started":"2022-08-17T09:09:34.383769Z","shell.execute_reply":"2022-08-17T09:09:34.394923Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import itertools\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, classification_report\n\nmetrics = ['accuracy',\n                tf.keras.metrics.AUC(),\n                tfa.metrics.CohenKappa(num_classes = 4),\n                tfa.metrics.F1Score(num_classes = 4),\n                tf.keras.metrics.Precision(), \n                tf.keras.metrics.Recall()]\n\ndef plot_loss(history):\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    \ndef plot_acc(history):\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    \n# It prints & plots the confusion matrix, normalization can be applied by setting normalize=True.\n    \ndef plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_roc_curves(y_true, y_pred, num_classes, class_labels):\n    \n    lb = LabelBinarizer()\n    lb.fit(y_true)\n    y_test = lb.transform(y_true)\n\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    # Plot all ROC curves\n    for i in range(num_classes):\n        fig, c_ax = plt.subplots(1,1, figsize = (6, 4))\n        c_ax.plot(fpr[i], tpr[i],\n                 label='ROC curve of class {0} (area = {1:0.4f})'\n                 ''.format(class_labels[i], roc_auc[i]))\n        c_ax.set_xlabel('False Positive Rate')\n        c_ax.set_ylabel('True Positive Rate')\n        c_ax.set_title('ROC curve of class {0}'.format(class_labels[i]))\n        c_ax.legend(loc=\"lower right\")\n        plt.show()\n    return roc_auc_score(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:09:34.397046Z","iopub.execute_input":"2022-08-17T09:09:34.397455Z","iopub.status.idle":"2022-08-17T09:09:36.798899Z","shell.execute_reply.started":"2022-08-17T09:09:34.397415Z","shell.execute_reply":"2022-08-17T09:09:36.798076Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, history, test_generator):\n    # Evaluate model\n    score = model.evaluate(test_generator, verbose=0)\n    print('\\nTest set accuracy:', score[1], '\\n')\n    \n    y_true = np.array(test_generator.labels)\n    y_pred = model.predict(test_generator, verbose = 1)\n    y_pred_classes = np.argmax(y_pred,axis = 1)\n    class_labels = list(test_generator.class_indices.keys())   \n    \n    print('\\n', sklearn.metrics.classification_report(y_true, y_pred_classes, target_names=class_labels), sep='')\n    confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n    plot_acc(history)\n    plt.show()\n    plot_loss(history)\n    plt.show()\n    plot_confusion_matrix(confusion_mtx, classes = class_labels)\n    plt.show()\n    print(\"ROC AUC score:\", plot_roc_curves(y_true, y_pred, 4, class_labels))","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:09:36.800091Z","iopub.execute_input":"2022-08-17T09:09:36.800413Z","iopub.status.idle":"2022-08-17T09:09:36.808934Z","shell.execute_reply.started":"2022-08-17T09:09:36.800380Z","shell.execute_reply":"2022-08-17T09:09:36.806665Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"vgg_model = generate_model('vgg16', 4)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T09:09:36.810288Z","iopub.execute_input":"2022-08-17T09:09:36.810613Z","iopub.status.idle":"2022-08-17T09:09:37.616160Z","shell.execute_reply.started":"2022-08-17T09:09:36.810580Z","shell.execute_reply":"2022-08-17T09:09:37.615288Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"vgg_model, vgg_history = train_model(vgg_model, train_generator, val_generator, 50, tf.keras.optimizers.SGD(lr=0.001, momentum=0.9), metrics)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T13:39:37.757801Z","iopub.execute_input":"2022-08-17T13:39:37.758172Z","iopub.status.idle":"2022-08-17T13:39:37.774038Z","shell.execute_reply.started":"2022-08-17T13:39:37.758140Z","shell.execute_reply":"2022-08-17T13:39:37.772081Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"evaluate_model(vgg_model, vgg_history, test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model.save(\"/kaggle/working/vgg_model_weights.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import load_img,img_to_array\nimage_path= df_test['image_path'][101]\nimg = load_img(image_path, target_size=(224,224,3)) # stores image in PIL format\nimage_array=img_to_array(img)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\ndisplay(Image.open(image_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.layers[-2].output])\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make model\nmodel = vgg_model\nlast_conv_layer_name =\"block5_conv3\"\n# Remove last layer's softmax\nmodel.layers[-1].activation = None\n\nimg_array=np.expand_dims(image_array, axis=0)\n# Prepare particular image \n\n# Generate class activation heatmap\nheatmap= make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.cm as cm\ndef save_and_display_gradcam(img_path, heatmap, cam_path, alpha=0.4):\n    # Load the original image\n    img = tf.keras.preprocessing.image.load_img(img_path)\n    img = tf.keras.preprocessing.image.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n    display(Image.open(cam_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_and_display_gradcam(image_path, heatmap,cam_path=\"/kaggle/working/GradCamTest.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"incres_model = generate_model('inceptionresnet', 4)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"incres_model, incres_history = train_model(incres_model, train_generator, val_generator, 50, tf.keras.optimizers.SGD(lr=0.001, momentum=0.9), metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(incres_model, incres_history, test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D,AveragePooling2D, BatchNormalization, PReLU, ReLU, SeparableConv2D\nfrom keras.models import Model, Sequential\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 64\nsecond_filters = 128\nthird_filters = 256\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\n# create a model with separable convolutional layers\ndef custom_model():\n    inputs = Input((224, 224, 3))\n    x = Conv2D(first_filters, kernel_size, activation = 'relu')(inputs)\n    x = Conv2D(first_filters, kernel_size, activation = 'relu')(x)\n    x = Conv2D(first_filters, kernel_size, activation = 'relu')(x)\n    x = MaxPooling2D(pool_size = pool_size)(x)\n    x = Dropout(dropout_conv)(x)\n    x = Conv2D(second_filters, kernel_size, activation ='relu')(x)\n    x = Conv2D(second_filters, kernel_size, activation ='relu')(x)\n    x = Conv2D(second_filters, kernel_size, activation ='relu')(x)\n    x = MaxPooling2D(pool_size = pool_size)(x)\n    x = Dropout(dropout_conv)(x)\n    x = Conv2D(third_filters, kernel_size, activation ='relu')(x)\n    x = Conv2D(third_filters, kernel_size, activation ='relu')(x)\n    x = Conv2D(third_filters, kernel_size, activation ='relu')(x)\n    x = MaxPooling2D(pool_size = pool_size)(x)\n    x = Dropout(dropout_conv)(x)\n    x = Flatten()(x)\n    x = Dense(4096)(x)\n    x = ReLU()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(4096)(x)\n    x = ReLU()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(4, activation = \"softmax\")(x)\n    model = Model(inputs = inputs, outputs = x)\n    model.summary\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = custom_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = train_model(model, train_generator, val_generator, 50, tf.keras.optimizers.SGD(lr=0.001, momentum=0.9), metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, history, test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_model = generate_model('inceptionv3', 4)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_model, inception_history = train_model(inception_model, train_generator, val_generator, 50, tf.keras.optimizers.SGD(lr=0.001, momentum=0.9), metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(inception_model, inception_history, test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}